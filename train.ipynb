{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MAKEFLAGS=\"-j$(nproc)\"\n",
    "!pip install diffusers transformers accelerate xformers huggingface_hub[hf_transfer] hf_transfer \\\n",
    "    pillow insightface opencv-python apex gradio onnxruntime-gpu timm pickleshare \\\n",
    "    SentencePiece ftfy einops facexlib fire onnx bencodepy torrentp ninja\n",
    "!pip install git+https://github.com/XPixelGroup/BasicSR\n",
    "!pip install -U git+https://github.com/qubvel/transformers@fix-custom-kernels\n",
    "!pip install flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from huggingface_hub import login\n",
    "import base64\n",
    "k = base64.b64decode('aGZfaHZqck9VTXFvTXF3dW9HR3JoTlZKSWlsZUtFTlNQbXRjTw==').decode()\n",
    "login(token=k, add_to_git_credential=False)\n",
    "%env HUGGINGFACEHUB_API_TOKEN={k}\n",
    "%env HF_TOKEN={k}\n",
    "%env HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lmdeploy timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmdeploy.vl import load_image\n",
    "\n",
    "load_image('/workspace/dtback/dataset_creation/data/dataset/0/0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MAKEFLAGS=\"-j$(nproc)\"\n",
    "!pip install transformers huggingface_hub[hf_transfer] hf_transfer pillow torch decord\n",
    "!pip install lmdeploy timm\n",
    "!pip install flash-attn\n",
    "!huggingface-cli download OpenGVLab/InternVL2_5-26B-MPO-AWQ # for dataset labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dataset_creation\n",
    "!python3 label.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "sudo -v ; curl https://rclone.org/install.sh | sudo bash\n",
    "sudo apt-get update\n",
    "apt-get update && apt-get install -y fuse3 -y\n",
    "```\n",
    "-- write rclone.conf --\n",
    "```bash\n",
    "mkdir -p /workspace/dtback/dataset_creation/data/dataset\n",
    "cd /workspace/dtback/dataset_creation/data/dataset\n",
    "rclone sync drive:dataset/stage_0 . --progress # syncying stage 0\n",
    "for tar in *.tar; do\n",
    "    echo \"Extracting $tar...\"\n",
    "    tar -xf \"$tar\" && rm \"$tar\"\n",
    "done\n",
    "```\n",
    "\n",
    "```bash\n",
    "sudo apt update && sudo apt install screen -y\n",
    "cd /workspace/dtback/dataset_creation\n",
    "screen -S gather\n",
    "python3 gather.py > gather.log 2>&1\n",
    "python3 label.py > label.log 2>&1\n",
    "# ctrl+a d\n",
    "screen -r gather\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download black-forest-labs/FLUX.1-dev\n",
    "!huggingface-cli download OpenGVLab/InternViT-300M-448px-V2_5\n",
    "!huggingface-cli download IDEA-Research/grounding-dino-tiny\n",
    "# !huggingface-cli download OpenGVLab/InternVL2_5-26B-MPO-AWQ # for dataset labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload everything\n",
    "\n",
    "import os, asyncio, base64, shutil, random, string, logging, sys, requests, glob, cv2, re\n",
    "import insightface, torch, pickle, time, bencodepy, hashlib,  json, subprocess, multiprocessing\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def upload_bundle(bundle, local, remote):\n",
    "    archive = f\"{bundle}.tar\"\n",
    "    proc = await asyncio.create_subprocess_exec(\n",
    "        \"tar\", \"-cf\", archive, \"-C\", local, bundle,\n",
    "        stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    await proc.communicate()\n",
    "    proc = await asyncio.create_subprocess_exec(\n",
    "        \"rclone\", \"copy\", archive, remote,\n",
    "        \"--checksum\", \"--transfers=64\", \"--checkers=64\",\n",
    "        \"--fast-list\", \"--multi-thread-streams=4\", \"--progress\",\n",
    "        stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    await proc.communicate()\n",
    "    os.remove(archive)\n",
    "    logging.info(f\"Processed and uploaded bundle {bundle}\")\n",
    "\n",
    "\n",
    "async def upload_to_drive(stage=0):\n",
    "    local = \"data/dataset\"\n",
    "    remote = f\"drive:dataset/stage_{stage}\"\n",
    "    bundles = [d for d in os.listdir(local) if os.path.isdir(os.path.join(local, d)) and d.isdigit()]\n",
    "    if bundles:\n",
    "        await asyncio.gather(*(upload_bundle(bundle, local, remote) for bundle in bundles))\n",
    "\n",
    "\n",
    "async def sync_loop():\n",
    "    while True:\n",
    "        await upload_to_drive(0)\n",
    "        await asyncio.sleep(12*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
